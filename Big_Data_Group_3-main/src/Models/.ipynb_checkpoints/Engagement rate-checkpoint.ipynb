{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb16faca",
   "metadata": {},
   "source": [
    "# Initialize pyspark environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9060c761",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "\n",
    "# initialize findspark with spark directory\n",
    "\n",
    "#ALWAYS HAVE TO BE CHANGED \n",
    "#path = \"/Users/konstantinlazarov/Desktop/Big_Data/PySpark/Week_5/spark\"\n",
    "path = \"/Users/Artur/spark\"\n",
    "findspark.init(path) \n",
    "\n",
    "# import pyspark\n",
    "import pyspark\n",
    "# create spark context\n",
    "sc = pyspark.SparkContext()\n",
    "# create spark session \n",
    "spark = pyspark.sql.SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61c0aed",
   "metadata": {},
   "source": [
    "# Import necessary packages and data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ef480a",
   "metadata": {},
   "source": [
    "#### Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea3c7e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import os \n",
    "import pickle\n",
    "\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "\n",
    "import pytz\n",
    "import emojis\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import ast\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "\n",
    "import tweepy\n",
    "import csv\n",
    "import time\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "import json\n",
    "from pandas.tseries.holiday import nearest_workday, \\\n",
    "    AbstractHolidayCalendar, Holiday, \\\n",
    "    USMartinLutherKingJr, USPresidentsDay, GoodFriday, \\\n",
    "    USMemorialDay, USLaborDay, USThanksgivingDay\n",
    "from datetime import date\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bc3875",
   "metadata": {},
   "source": [
    "#### Import the twitter data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bbb854b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1595676"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_brands = [\"healthyfood\",\n",
    "               \"healthylifestyle\",\n",
    "               \"_vegan_\",\n",
    "               \"keto\",\n",
    "               \"ketodiet\",\n",
    "               \"ketolifestyle\",\n",
    "               \"veganism\",\n",
    "               \"vegetarian\"]\n",
    "from re import search\n",
    "\n",
    "\n",
    "\n",
    "data_dir = \".././../data/Topic_vegan/\"\n",
    "tweet_files = [os.path.join(data_dir, obs) for obs in os.listdir(data_dir)]\n",
    "\n",
    "\n",
    "\n",
    "files_brand = [file for file in tweet_files if (file.find(list_brands[2]) != -1)]\n",
    "files_brand               \n",
    "               \n",
    "df_json = spark.read.option(\"multiline\",\"true\").json(files_brand)  \n",
    "df_json.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d01c21b",
   "metadata": {},
   "source": [
    "# Predict the engagement rate of a tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4927556d",
   "metadata": {},
   "source": [
    "In this notebook, we are going to predict the engagement rate of tweets. Further, it will be interesting to see the driving factors behind the engagement rate. This can be valuable information when creating an own social media brand or when you want to increase the reach of your tweets.\n",
    "\n",
    "We start by creating a basetable for this model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5d9074",
   "metadata": {},
   "source": [
    "## 1. Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc88f89",
   "metadata": {},
   "source": [
    "First, we start by defining our dependent variable. The engagement rate has already been discussed in the data exploration section. We will use the same definition in order to create a model to predict the engagement rate. Below, we repeat this definition:\n",
    "\n",
    "Engagement on Twitter is measured by the number of retweets, follows, replies, favorites, and other people’s reactions to your tweets, including the clicks on the links and hashtags in those tweets. Your Twitter engagement rate is your engagement figure divided by the number of impressions on the tweet.\n",
    "\n",
    "In order to predict the engagement of a tweet, we will use the following variables:\n",
    "\n",
    "\n",
    "1) number of words\n",
    "2) number of hashtags\n",
    "3) number of tags\n",
    "4) number of emojis\n",
    "5) the month\n",
    "6) day of the month\n",
    "7) day of the week\n",
    "8) hour of the day\n",
    "9) the language\n",
    "10) tweeted by an influencer or not\n",
    "11) tweeted quote\n",
    "12) source of the tweet\n",
    "13) presence of a symbol\n",
    "14) Indicator if a mention to another user was made\n",
    "15) The media type present\n",
    "16) The number of text characters in the tweet\n",
    "\n",
    "\n",
    "The goal of our model is not only to predict the engagement rate, but look at the underlying drivers of the engagement rate. This way, we aim to optimize our engagement rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54bcccf2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GroupedData' object has no attribute 'toPandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b10a0519c75e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_json\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"extended_entities.media.type\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GroupedData' object has no attribute 'toPandas'"
     ]
    }
   ],
   "source": [
    "a = df_json.groupBy(F.col(\"extended_entities.media.type\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5488cba0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Column '``' does not exist. Did you mean one of the following? [id, geo, lang, user, place, id_str, source, entities, metadata, favorited, full_text, retweeted, truncated, created_at, coordinates, contributors, quoted_status, retweet_count, favorite_count, withheld_scope, is_quote_status, quoted_status_id, retweeted_status, extended_entities, display_text_range, possibly_sensitive, in_reply_to_user_id, quoted_status_id_str, in_reply_to_status_id, withheld_in_countries, in_reply_to_screen_name, in_reply_to_user_id_str, in_reply_to_status_id_str];\n'Project [', ', ', ', ', ', ', ', ', ', ', ', ']\n+- Relation [contributors#0,coordinates#1,created_at#2,display_text_range#3,entities#4,extended_entities#5,favorite_count#6L,favorited#7,full_text#8,geo#9,id#10L,id_str#11,in_reply_to_screen_name#12,in_reply_to_status_id#13L,in_reply_to_status_id_str#14,in_reply_to_user_id#15L,in_reply_to_user_id_str#16,is_quote_status#17,lang#18,metadata#19,place#20,possibly_sensitive#21,quoted_status#22,quoted_status_id#23L,... 9 more fields] json\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-da1d71c8b236>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Select the interesting variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m df_json_engagement = df_json.select(F.col(''),\n\u001b[0m\u001b[1;32m      3\u001b[0m                                    \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                    \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                    \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   2021\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Alice'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Bob'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2022\u001b[0m         \"\"\"\n\u001b[0;32m-> 2023\u001b[0;31m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2024\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkSession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Column '``' does not exist. Did you mean one of the following? [id, geo, lang, user, place, id_str, source, entities, metadata, favorited, full_text, retweeted, truncated, created_at, coordinates, contributors, quoted_status, retweet_count, favorite_count, withheld_scope, is_quote_status, quoted_status_id, retweeted_status, extended_entities, display_text_range, possibly_sensitive, in_reply_to_user_id, quoted_status_id_str, in_reply_to_status_id, withheld_in_countries, in_reply_to_screen_name, in_reply_to_user_id_str, in_reply_to_status_id_str];\n'Project [', ', ', ', ', ', ', ', ', ', ', ', ']\n+- Relation [contributors#0,coordinates#1,created_at#2,display_text_range#3,entities#4,extended_entities#5,favorite_count#6L,favorited#7,full_text#8,geo#9,id#10L,id_str#11,in_reply_to_screen_name#12,in_reply_to_status_id#13L,in_reply_to_status_id_str#14,in_reply_to_user_id#15L,in_reply_to_user_id_str#16,is_quote_status#17,lang#18,metadata#19,place#20,possibly_sensitive#21,quoted_status#22,quoted_status_id#23L,... 9 more fields] json\n"
     ]
    }
   ],
   "source": [
    "# Select the interesting variables\n",
    "df_json_engagement = df_json.select(F.col('created_at'),\n",
    "                                   F.col('entities.symbols'),\n",
    "                                   F.col(''),\n",
    "                                   F.col(''),\n",
    "                                   F.col(''),\n",
    "                                   F.col(''),\n",
    "                                   F.col(''),\n",
    "                                   F.col(''),\n",
    "                                   F.col(''),\n",
    "                                   F.col(''),\n",
    "                                   F.col(''),\n",
    "                                   F.col(''),\n",
    "                                   F.col(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70af49f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4aa35d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6ccf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define puncutation and stopwords\n",
    "PUNCTUATION = [char for char in punctuation if char not in [\"!\", \"@\", \"#\"]]\n",
    "STOPWORDS = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8521a20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to remove punctuation\n",
    "def remove_punct(text):\n",
    "    ## Remove punctuation\n",
    "    text = \"\".join([char for char in text if char not in PUNCTUATION])\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a459ccd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to remove stopwords\n",
    "def remove_stops(text):\n",
    "    ## Tokenize\n",
    "    word_tokens = word_tokenize(text)\n",
    "\n",
    "    ## Remove stopwords\n",
    "    text_tokenized = [word for word in word_tokens if word not in STOPWORDS]\n",
    "\n",
    "    ## Detokenize\n",
    "    text = TreebankWordDetokenizer().detokenize(text_tokenized)\n",
    "\n",
    "    ## Return\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c844e1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to remove stopwords\n",
    "def remove_numbers(text):\n",
    "    ## Remove numbers\n",
    "    text = text.replace(\"0\", \"\")\n",
    "    text = text.replace(\"1\", \"\")\n",
    "    text = text.replace(\"2\", \"\")\n",
    "    text = text.replace(\"3\", \"\")\n",
    "    text = text.replace(\"4\", \"\")\n",
    "    text = text.replace(\"5\", \"\")\n",
    "    text = text.replace(\"6\", \"\")\n",
    "    text = text.replace(\"7\", \"\")\n",
    "    text = text.replace(\"8\", \"\")\n",
    "    text = text.replace(\"9\" ,\"\")\n",
    "\n",
    "    ## Return\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1183ed54",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define function to count hashtags\n",
    "def get_hashtags(text):\n",
    "    counter = 0\n",
    "    for letter in text:\n",
    "        if letter == \"#\":\n",
    "            counter += 1\n",
    "    return(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a73c718",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define function to count tags\n",
    "def get_tags(text):\n",
    "    counter = 0\n",
    "    for letter in text:\n",
    "        if letter == \"@\":\n",
    "            counter += 1\n",
    "    return(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dbda59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to count exclamation marks\n",
    "def get_exclamation_marks(text):\n",
    "    counter = 0\n",
    "    for letter in text:\n",
    "        if letter ==  \"!\":\n",
    "            counter += 1\n",
    "    return(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b70a3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define number of upper case words\n",
    "def count_upper_case_words(text):\n",
    "    counter = 0\n",
    "    \n",
    "    ## Tokenize\n",
    "    word_tokens = word_tokenize(text)\n",
    "\n",
    "    ## Check for uppercase words\n",
    "    for word in word_tokens:\n",
    "        if word.isupper():\n",
    "            counter += 1\n",
    "    return(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f4c1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the function to extract the sentiment\n",
    "def get_sentiment(text):\n",
    "    \n",
    "    ## Initialize sentiment analyzer\n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    "\n",
    "    ## Get sentiment dict\n",
    "    sentiment_dict = sid_obj.polarity_scores(text)\n",
    "    \n",
    "    ## Get positive sentiment score\n",
    "    pos_sentiment = sentiment_dict[\"pos\"]\n",
    "    \n",
    "    ## Return positive sentiment score\n",
    "    return(pos_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d550a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to remove links\n",
    "def remove_urls(text):\n",
    "    ## Remove links\n",
    "    text = re.sub(r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))''', \" \", text)\n",
    "    \n",
    "    ## Return\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b86526",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Number of days since account has been created (since last day of scraping)\n",
    "#basetable = basetable.withColumn(\"account_age\", F.datediff(F.lit(\"2022-10-11\"), F.col(\"user.created_at\")))\n",
    "\n",
    "## Inspect basetable\n",
    "#basetable.select(F.lit(\"2022-10-11\"), F.col(\"user.created_at\"), F.col(\"account_age\")).show(5, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e78b803a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to get help get the number of media types included in the tweet\n",
    "def adjust_nr_media(number):\n",
    "    if number == -1:\n",
    "        number = 0\n",
    "        \n",
    "    return number\n",
    "    \n",
    "\n",
    "adjust_nr_media_udf = F.udf(adjust_nr_media)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e67b69ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to get the first media element\n",
    "def get_media_type(media):\n",
    "    if media == None:\n",
    "        media = 'no_media'\n",
    "    else:\n",
    "        media = media[0]\n",
    "       \n",
    "    return media\n",
    "    \n",
    "\n",
    "get_media_type_udf = F.udf(get_media_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff577fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to get the first media element\n",
    "def get_nr_text_characters(text_rang):\n",
    "    if media == None:\n",
    "        media = 'no_media'\n",
    "    else:\n",
    "        media = media[0]\n",
    "       \n",
    "    return media\n",
    "    \n",
    "\n",
    "get_media_type_udf = F.udf(get_nr_text_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3d7367f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_json_engagement.withColumn(\"nr_media_elements\", size(\"type\"))\\\n",
    "                       .withColumn(\"nr_media_elements\", adjust_nr_media_udf(\"nr_media_elements\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "62d174c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                type|\n",
      "+--------------------+\n",
      "|             [photo]|\n",
      "|             [video]|\n",
      "|                null|\n",
      "|             [video]|\n",
      "|             [video]|\n",
      "|             [photo]|\n",
      "|                null|\n",
      "|             [photo]|\n",
      "|             [photo]|\n",
      "|                null|\n",
      "|             [video]|\n",
      "|                null|\n",
      "|                null|\n",
      "|             [photo]|\n",
      "|                null|\n",
      "|             [video]|\n",
      "|             [video]|\n",
      "|[photo, photo, ph...|\n",
      "|             [video]|\n",
      "|                null|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_json_engagement = df_json.select(F.col('extended_entities.media.type'))\n",
    "df_json_engagement.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789e8842",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "86f3e9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|                type|media_type|\n",
      "+--------------------+----------+\n",
      "|             [photo]|     photo|\n",
      "|             [video]|     video|\n",
      "|                null|  no_media|\n",
      "|             [video]|     video|\n",
      "|             [video]|     video|\n",
      "|             [photo]|     photo|\n",
      "|                null|  no_media|\n",
      "|             [photo]|     photo|\n",
      "|             [photo]|     photo|\n",
      "|                null|  no_media|\n",
      "|             [video]|     video|\n",
      "|                null|  no_media|\n",
      "|                null|  no_media|\n",
      "|             [photo]|     photo|\n",
      "|                null|  no_media|\n",
      "|             [video]|     video|\n",
      "|             [video]|     video|\n",
      "|[photo, photo, ph...|     photo|\n",
      "|             [video]|     video|\n",
      "|                null|  no_media|\n",
      "+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df_json_engagement.withColumn(\"media_type\", get_media_type_udf('type'))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662831e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b043663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a31cce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9f9041",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cdb20c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
